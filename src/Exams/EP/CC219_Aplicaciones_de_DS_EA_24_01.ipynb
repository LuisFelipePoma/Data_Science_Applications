{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfWr1IM-DMap"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "**Parcial Aplicaciones de Data-Science**\n",
    "\n",
    "**Semestre 2024-01**\n",
    "\n",
    "**Nombre del Alumno:**  Luis Felipe Poma Astete\n",
    "\n",
    "**Código:**  202110902\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TJcZkz6D2cgg"
   },
   "source": [
    "## **CASO DE ANALISIS:** CLASIFICACIÓN DE POEMAS\n",
    "\n",
    "El dataset consta de un conjunto de 786 poemas en ingles clasificados como Affection,Environment,Music and Death para entrenamiento y 150 para prueba.\n",
    "\n",
    "Se pide hacer el prepocesamiento de datos, creación de la bolsa de palabras y platear e intrepretar un clasificador naive bayes con los datos.\n",
    "\n",
    "\n",
    "\n",
    "## **Normalizacion del Texto**\n",
    "\n",
    "**1) Creacion de Corpus**\n",
    "\n",
    "A partir del archivos Poem_classification - test_data.csv y Poem_classification - train_data.csv, crear dos (2) corpus que consideren lo siguiente:\n",
    "\n",
    "**Corpus #1 Train:**  Conteniendo solo el texto de entrenamiento sin etiquetas\n",
    "\n",
    "**Corpus #2 Test:**  Conteniendo solo el texto de test sin etiquetas\n",
    "\n",
    "\n",
    "\n",
    "**2) Normalizar corpus**\n",
    "\n",
    "* Tokenizar y convertir a minusculas\n",
    "* Eliminar los tokens que sean signos de puntuación\n",
    "* Transformar cada token a su lema\n",
    "* Elimine los tokens no alfabeticos y menores a tres (3) dígitos\n",
    "\n",
    "## **BOLSA DE PALABRAS**\n",
    "\n",
    "**3) Bag of Words**\n",
    "\n",
    "* Devuelva un arreglo con las frecuencia de cada uno de los tokens unicos por documento. Utilice la estrategia de Vector de Frecuencias.\n",
    "* Devuelva un arreglo TF-IDF para cada documento.\n",
    "\n",
    "\n",
    "## **CLASIFICADOR BAYESIANO**\n",
    "**4) Clasificador bayeciano**\n",
    "\n",
    "* Realice el clasificador Naive Bayes con los vectores de frecuencia\n",
    "* Realice el clasificador Naive Bayes con los vectores TF-IDF\n",
    "\n",
    "**5) Prueba**\n",
    "\n",
    "* Con el corpus de test pruebe el rendimiento de ambos modelos utilize las metricas Presicion, Recall y F1-SCORE\n",
    "\n",
    "## **INTERPRETACIÓN**\n",
    "\n",
    "**6) Interpretación de resultados**\n",
    "\n",
    "* Explique los resultados obtenidos en el apartado 4, describa el mejor modelo e interprete el porque de su rendimiento correpondiente en relación a las metricas.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i0BvBs7ccB0I"
   },
   "source": [
    "## **SOLUCIÓN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FnEj662PRJ3o"
   },
   "source": [
    "## **Normalización del Texto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "11h7DdVwXE1w",
    "outputId": "ed62bb2f-822b-4412-8b84-445f0311cb9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1) Creacion de Corpus**\\n\\nA partir del archivos Poem_classification - test_data.csv y Poem_classification - train_data.csv, crear dos (2) corpus que consideren lo siguiente:\\n\\n**Corpus #1 Train:**  Conteniendo solo el texto de entrenamiento sin etiquetas\\n\\n**Corpus #2 Test:**  Conteniendo solo el texto de test sin etiquetas\\n\\n2) Normalizar corpus\\n\\n\\n* Tokenizar y convertir a minusculas\\n* Eliminar los tokens que sean signos de puntuación\\n* Transformar cada token a su lema\\n* Elimine los tokens no alfabeticos y menores a tres (3) dígitos\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "1) Creacion de Corpus**\n",
    "\n",
    "A partir del archivos Poem_classification - test_data.csv y Poem_classification - train_data.csv, crear dos (2) corpus que consideren lo siguiente:\n",
    "\n",
    "**Corpus #1 Train:**  Conteniendo solo el texto de entrenamiento sin etiquetas\n",
    "\n",
    "**Corpus #2 Test:**  Conteniendo solo el texto de test sin etiquetas\n",
    "\n",
    "2) Normalizar corpus\n",
    "\n",
    "\n",
    "* Tokenizar y convertir a minusculas\n",
    "* Eliminar los tokens que sean signos de puntuación\n",
    "* Transformar cada token a su lema\n",
    "* Elimine los tokens no alfabeticos y menores a tres (3) dígitos\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"./Poem Classification/Poem_classification - train_data.csv\")\n",
    "data_test = pd.read_csv(\"./Poem Classification/Poem_classification - test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>Poem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Music</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Music</td>\n",
       "      <td>In the thick brushthey spend the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Genre                                               Poem\n",
       "0  Music                                                NaN\n",
       "1  Music                In the thick brushthey spend the..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>Poem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Music</td>\n",
       "      <td>A woman walks by the bench I’m sitting onwith ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Music</td>\n",
       "      <td>Because I am a boy, the untouchability of beau...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Genre                                               Poem\n",
       "0  Music  A woman walks by the bench I’m sitting onwith ...\n",
       "1  Music  Because I am a boy, the untouchability of beau..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpiamos los datos nulos de `train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 841 entries, 0 to 840\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Genre   841 non-null    object\n",
      " 1   Poem    837 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 13.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 837 entries, 1 to 840\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Genre   837 non-null    object\n",
      " 1   Poem    837 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 19.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora normalizamos el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pms_l\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pms_l\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\pms_l\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    # Tokenizar y convertir a minúsculas\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    # Eliminar signos de puntuación y tokens no alfabéticos\n",
    "    tokens = [token for token in tokens if token.isalpha()]\n",
    "\n",
    "    # Lematizar y eliminar palabras de menos de tres caracteres\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if len(token) > 3]\n",
    "\n",
    "    # Eliminar stopwords\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['normalized_text'] = data_train['Poem'].apply(normalize_text)\n",
    "data_test['normalized_text'] = data_test['Poem'].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo de documentos normalizados en el corpus de entrenamiento:\n",
      "Documento 1: thick brushthey spend hottest part soaking hoovesin trickle mountain water ravine hoardson behalf oleander\n",
      "Documento 2: storm generous something easy surrender sitting window step garden bored\n",
      "Documento 3: mendieta carry around matin star hold hand would wake radiate shimmer gleam morning would measure wingspan idea taking night would\n",
      "Documento 4: sherrard portent memory stevenshow hard carry score adult back look carrion need distressof loyalty requires pain\n",
      "Documento 5: marley bavaria november brilliant morning fishing boat dream dying midwinter world covered light dream\n"
     ]
    }
   ],
   "source": [
    "# etiquetas de entrenamiento y prueba\n",
    "label_train = data_train[\"Genre\"]\n",
    "label_test = data_test[\"Genre\"]\n",
    "\n",
    "# texto de entrenamiento sin etiquetas\n",
    "corpus_train = data_train[\"normalized_text\"].tolist()\n",
    "\n",
    "# texto de prueba sin etiquetas\n",
    "corpus_test = data_test[\"normalized_text\"].tolist()\n",
    "\n",
    "# Ejemplo de visualización de los primeros documentos normalizados en el corpus de entrenamiento\n",
    "print(\"Ejemplo de documentos normalizados en el corpus de entrenamiento:\")\n",
    "for i in range(5):\n",
    "    print(f\"Documento {i+1}: {corpus_train[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vS4inqPTRn3y"
   },
   "source": [
    "## **BOLSA DE PALABRAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "1OaV_5pebLO_",
    "outputId": "fb1c4509-ee63-4494-b341-045501dbcc7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n3) Bag of Words\\n\\n* Devuelva un arreglo con las frecuencia de cada uno de los tokens unicos por documento. Utilice la estrategia de Vector de Frecuencias.\\n* Devuelva un arreglo TF-IDF para cada documento.\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "3) Bag of Words\n",
    "\n",
    "* Devuelva un arreglo con las frecuencia de cada uno de los tokens unicos por documento. Utilice la estrategia de Vector de Frecuencias.\n",
    "* Devuelva un arreglo TF-IDF para cada documento.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hallamos el documento con mayor tamaño, luego tomarlo como parametro de cuantas palabras como maximo tendra nuestro vocabulario, asi evitando que existan muchos ceros en nuestro `BOW`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontramos el maximo de tokens unicos en el corpus de entrenamiento\n",
    "max_len = max([len(doc.split()) for doc in corpus_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(max_features=max_len + 10, stop_words=\"english\")\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=max_len + 10, stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora creamos nuestro ``Bag Of Words``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo de tokens únicos (vocabulario) generado por CountVectorizer:\n",
      "['away' 'black' 'blue' 'body' 'child' 'come' 'dark' 'dead' 'death' 'door'\n",
      " 'earth' 'eye' 'face' 'field' 'flower' 'foot' 'grass' 'green' 'hand'\n",
      " 'heart' 'hour' 'know' 'leaf' 'life' 'light' 'like' 'little' 'long' 'look'\n",
      " 'love' 'make' 'moon' 'morning' 'mother' 'night' 'river' 'said' 'song'\n",
      " 'star' 'summer' 'tell' 'thing' 'think' 'time' 'tree' 'water' 'white'\n",
      " 'wind' 'woman' 'word'] \n",
      "\n",
      "thick brushthey spend hottest part soaking hoovesin trickle mountain water ravine hoardson behalf oleander\n",
      "\n",
      "Ejemplo de matriz de frecuencias (Bag of Words) para el primer documento de entrenamiento:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ajustar CountVectorizer al corpus de entrenamiento\n",
    "X_train_count = count_vectorizer.fit_transform(corpus_train).toarray()\n",
    "# Ajustar TfidfVectorizer al corpus de entrenamiento\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(corpus_train).toarray()\n",
    "\n",
    "# Ejemplo de visualización del vocabulario generado por CountVectorizer\n",
    "bow_vectorizer = count_vectorizer.get_feature_names_out()\n",
    "print(f\"Ejemplo de tokens únicos (vocabulario) generado por CountVectorizer:\")\n",
    "print(bow_vectorizer[:50], \"\\n\")  # Mostrar los primeros 50 tokens únicos\n",
    "\n",
    "print(corpus_train[0])\n",
    "# Ejemplo de visualización de la matriz de frecuencias (Bag of Words) para el primer documento de entrenamiento\n",
    "print(\n",
    "    \"\\nEjemplo de matriz de frecuencias (Bag of Words) para el primer documento de entrenamiento:\"\n",
    ")\n",
    "# imprimir en forma de matriz\n",
    "X_train_count[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ejemplo de tokens únicos (vocabulario) generado por TfidfVectorizer:\n",
      "['away' 'black' 'blue' 'body' 'child' 'come' 'dark' 'dead' 'death' 'door'\n",
      " 'earth' 'eye' 'face' 'field' 'flower' 'foot' 'grass' 'green' 'hand'\n",
      " 'heart' 'hour' 'know' 'leaf' 'life' 'light' 'like' 'little' 'long' 'look'\n",
      " 'love' 'make' 'moon' 'morning' 'mother' 'night' 'river' 'said' 'song'\n",
      " 'star' 'summer' 'tell' 'thing' 'think' 'time' 'tree' 'water' 'white'\n",
      " 'wind' 'woman' 'word']\n",
      "\n",
      "Ejemplo de matriz TF-IDF para el primer documento de entrenamiento:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo de visualización de la matriz TF-IDF para el primer documento de entrenamiento\n",
    "bow_tfidf = tfidf_vectorizer.get_feature_names_out()\n",
    "print(f\"\\nEjemplo de tokens únicos (vocabulario) generado por TfidfVectorizer:\")\n",
    "print(bow_tfidf[:50])  # Mostrar los primeros 50 tokens únicos\n",
    "\n",
    "# Ejemplo de visualización de la matriz TF-IDF para el primer documento de entrenamiento\n",
    "print(\"\\nEjemplo de matriz TF-IDF para el primer documento de entrenamiento:\")\n",
    "X_train_tfidf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los arreglos de frecuencias y TF-IDF para el corpus de prueba\n",
    "X_test_count = count_vectorizer.transform(corpus_test)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CLASIFICADOR BAYESIANO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n4) Clasificador bayeciano\\n\\n* Realice el clasificador Naive Bayes con los vectores de frecuencia\\n* Realice el clasificador Naive Bayes con los vectores TF-IDF\\n\\n5) Prueba\\n\\n* Con el corpus de test pruebe el rendimiento de ambos modelos utilize las metricas Presicion, Recall y F1-SCORE\\n\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "4) Clasificador bayeciano\n",
    "\n",
    "* Realice el clasificador Naive Bayes con los vectores de frecuencia\n",
    "* Realice el clasificador Naive Bayes con los vectores TF-IDF\n",
    "\n",
    "5) Prueba\n",
    "\n",
    "* Con el corpus de test pruebe el rendimiento de ambos modelos utilize las metricas Presicion, Recall y F1-SCORE\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar y entrenar el clasificador Naive Bayes con vectores de frecuencia\n",
    "nb_freq = MultinomialNB()\n",
    "\n",
    "nb_freq.fit(X_train_count, label_train)\n",
    "\n",
    "# Inicializar y entrenar el clasificador Naive Bayes con vectores TF-IDF\n",
    "nb_tfidf = MultinomialNB()\n",
    "nb_tfidf.fit(X_train_tfidf, label_train)\n",
    "\n",
    "# Predecir las etiquetas para el corpus de prueba usando ambos modelos\n",
    "y_pred_freq = nb_freq.predict(X_test_count)\n",
    "y_pred_tfidf = nb_tfidf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados del clasificador Naive Bayes con vectores de frecuencia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Affection       0.94      0.34      0.50       100\n",
      "       Death       0.23      0.38      0.29        13\n",
      " Environment       0.30      0.44      0.35        25\n",
      "       Music       0.13      0.58      0.21        12\n",
      "\n",
      "    accuracy                           0.38       150\n",
      "   macro avg       0.40      0.44      0.34       150\n",
      "weighted avg       0.71      0.38      0.43       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el rendimiento de los modelos con métricas de clasificación\n",
    "print(\"Resultados del clasificador Naive Bayes con vectores de frecuencia:\")\n",
    "print(classification_report(label_test, y_pred_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados del clasificador Naive Bayes con vectores TF-IDF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Affection       0.90      0.19      0.31       100\n",
      "       Death       0.19      0.38      0.25        13\n",
      " Environment       0.24      0.36      0.29        25\n",
      "       Music       0.11      0.58      0.18        12\n",
      "\n",
      "    accuracy                           0.27       150\n",
      "   macro avg       0.36      0.38      0.26       150\n",
      "weighted avg       0.67      0.27      0.29       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nResultados del clasificador Naive Bayes con vectores TF-IDF:\")\n",
    "print(classification_report(label_test, y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **INTERPRETACIÓN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6) Interpretación de resultados**\\n\\n* Explique los resultados obtenidos en el apartado 4, describa el mejor modelo e interprete el porque de su rendimiento correpondiente en relación a las metricas.\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''6) Interpretación de resultados**\n",
    "\n",
    "* Explique los resultados obtenidos en el apartado 4, describa el mejor modelo e interprete el porque de su rendimiento correpondiente en relación a las metricas.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mejor Modelo y Interpretación:**\n",
    "\n",
    "- Al comparar ambos modelos, el rendimiento del modelo con vectores de frecuencia parece ser ligeramente mejor en términos de precisión, recall y F1-score en la mayoría de las categorías en comparación con el modelo TF-IDF. Sin embargo, ambos modelos muestran limitaciones significativas, como una baja capacidad para identificar correctamente poemas en algunas categorías y una alta tasa de falsos positivos. El modelo con vectores de frecuencia tiende a generalizar un poco mejor en la mayoría de las categorías.\n",
    "  \n",
    "- El rendimiento deficiente en ambos modelos puede atribuirse a varios factores, como la complejidad y la naturaleza subjetiva de la clasificación de poemas en estas categorías específicas, así como la falta de datos de entrenamiento representativos (con solo 786 registros) y la simplicidad inherente del modelo Naive Bayes, que tiene sus limitaciones. En este caso, sería recomendable el uso de modelos más avanzados basados en redes neuronales para mejorar el rendimiento.\n",
    "  \n",
    "- Además, en intentos anteriores no se utilizó el parámetro `max_features` en los Bag of Words (BOWs), lo que resultó en bolsas de palabras con muchos ceros. Como consecuencia, al entrenar los modelos, se obtuvieron métricas muy dispares entre las categorías y una precisión (accuracy) por debajo de `0.2` con ambos BOWs. Sin embargo, al definir `max_features` como un parámetro en CountVectorizer, mejoró el rendimiento de los modelos. El modelo que utilizaba `CountVectorizer` aumentó su precisión a `0.39`, mientras que el modelo con `TfidfVectorizer` mejoró su precisión a `0.26`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eweCxQoJT8Ed"
   },
   "source": [
    "Una vez desarrolladas todas las operaciones solicitadas, no olvide adjuntar como respuesta a esta evaluación:\n",
    "\n",
    "* **Este Notebook** con sus datos personales conteniendo su solución\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
