{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmozbMh5CEAH"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "527lRI0zDtC2"
      },
      "source": [
        "<h3 align=\"center\"><b>TA1:</b> NLP - Normalización de textos </h3>\n",
        "<h3 align=\"center\">2023-2</h3>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfWr1IM-DMap"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Nombre del Alumno:**  Luis Felipe Poma Astete\n",
        "\n",
        "**Código:**  u202110902\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYdJ6qZIwWnQ"
      },
      "source": [
        "### **NLP: Normalización de textos y Bolsa de Palabras**\n",
        "\n",
        "* El corpus que se normalizará consiste en una serie de artículos obtenidos de la web \"https://www.elmundotoday.com/\".\n",
        "\n",
        "\n",
        "* Estos artículos se encuentran en el fichero csv **corpus_mundo_today.csv** que deberá adjuntar al notebook.\n",
        "\n",
        "\n",
        "* Este CSV esta formado por 3 campos que son:\n",
        "    - Tema\n",
        "    - Título\n",
        "    - Texto\n",
        "    \n",
        "    \n",
        "* El ejercicio consiste en Normalizar este ***Corpus*** tomando el *título* y *texto* como contenido de cada documento.\n",
        "\n",
        "Puede utilizar indistintamente las librerias **NLTK** y **Spacy** para el preprocesamiento (normalización) del texto.\n",
        "\n",
        "\n",
        "## Ejercicios de Nomalización solicitados:\n",
        "\n",
        "* Dada una lista en la que cada elemento de la misma tiene el contenido (título + texto) de cada documento del corpus se pide:\n",
        "<span></span><br><br>\n",
        "    1. **Crear una función que devuelva los documentos *Tokenizados* (una lista de listas) y con los tokens (palabras) en minúsculas.**\n",
        "        * **input**: lista de documentos (lista de Strings).\n",
        "        * **output**: lista de listas, en la que cada lista contiene los tokens del documento.\n",
        "<span></span><br><br>\n",
        "    2. **Crear una función que elimine los tokens que sean signos de puntuación y *Stop-Words*.**\n",
        "        * **input**: lista de listas, en la que cada lista contiene los tokens del documento.\n",
        "        * **output**: lista de listas, en la que cada lista contiene los tokens del documento.\n",
        "<span></span><br><br>\n",
        "    3. **Crear una función que transforme cada token a su lema (*Lematización*)**\n",
        "        * **input**: lista de listas, en la que cada lista contiene los tokens del documento.\n",
        "        * **output**: lista de listas, en la que cada lista contiene los tokens del documento.\n",
        "<span></span><br><br>\n",
        "    4. **Crear una función que elimine todos los tokens que no sean *Nombres* (NOUN, PROPN), *Verbos*, *Advervios* o *Adjetivos*.**\n",
        "        * **input**: lista de listas, en la que cada lista contiene los tokens del documento.\n",
        "        * **output**: lista de listas, en la que cada lista contiene los tokens del documento.\n",
        " <span></span><br><br>       \n",
        "    5. **Función que dada una lista de documentos, devuelva los documentos normalizados. Este ejercicio ya esta hecho y simplemente tiene que funcionar llamando a las 4 funciones anteriores.**\n",
        "        * **input**: lista de documentos (lista de Strings).\n",
        "        * **output**: lista de listas, en la que cada lista contiene los tokens del documento normalizados.\n",
        "\n",
        "\n",
        "* Finalizada la normalización anterior, se pide:\n",
        "\n",
        "    6. **Crear una función que dada una lista de documentos (*corpus*) tokenizados, elimine del corpus aquellos tokens que aparecen menos de 'N' veces (N=10) en el corpus**\n",
        "        * **input**: lista de listas, en la que cada lista contiene los tokens del documento normalizados.\n",
        "        * **input**: 'N' -> Parámetro que nos indica el número mínimo de apariciones de la palabra en el corpus.\n",
        "        * **output**: lista de listas, en la que cada lista contiene los tokens del documento normalizados.\n",
        "<span></span><br><br>\n",
        "   \n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sv6qkBgRwWnX"
      },
      "source": [
        "## Ejercicios de Nomalización:\n",
        "\n",
        "* Leemos el corpus y pasamos los documentos (Título + Texto) a una lista"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MtvRq_btwWnY"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'El Gobierno español sumará a Junqueras las condenas que no vaya a cumplir Puigdemont Después del revés recibido por el Gobierno de España tras la puesta en libertad de Carles Puigdemont por parte de la justicia alemana, el juez Pablo Llarena ha decidido esta semana, a instancias del Ejecutivo, que sumará a Oriol Junqueras las condenas que no vaya a cumplir el líder del PDeCAT. El exvicepresidente de Cataluña, que permanece en la prisión madrileña de Estremera desde el pasado dos de noviembre, asumiría por tanto todos los delitos atribuidos a Carles Puigdemont y, de esta manera, el Tribunal Supremo se asegura de que los actos del expresidente catalán durante la última legislatura no quedan impunes, ya que “Junqueras pagará por todos y cada uno de ellos”. Con esta maniobra ideada para burlar la justicia alemana, el líder de Esquerra Republicana se enfrenta a 50 años más de prisión. “Seguiremos adelante aunque a Junqueras le caigan cien años más, nadie nos va a parar”, ha dicho hoy Carles Puigdemont desde Alemania. “Haré lo que tenga que hacer y si Junqueras se tiene que sacrificar por ello, lo asumiré con resignación y determinación”, ha prometido. “Seguim!”, tuiteaba poco después de trascender la decisión de Llarena. Según fuentes anónimas del poder judicial, se está barajando también la posibilidad de añadir a la pena de Oriol Junqueras las condenas que puedan imponerse en el futuro a Iñaki Urdangarin, Rodrigo Rato o Esperanza Aguirre, entre otros, así como la de un delito de robo con fuerza ocurrido hace una semana en Huesca y del que la policía ha sido incapaz de encontrar al culpable.'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs_file = 'corpus_mundo_today.csv'\n",
        "docs_list = list()\n",
        "file_txt = open(docs_file, encoding=\"utf8\").read()\n",
        "for line in file_txt.split('\\n'):\n",
        "    line = line.split('||')\n",
        "    docs_list.append(line[1] + ' ' + line[2])\n",
        "docs_list = docs_list[1:] # Elimino la cabecera del fichero\n",
        "docs_list[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\pms_l\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import spacy\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nlp = spacy.load(\"es_core_news_sm\")\n",
        "nltk.download(\"wordnet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7A1rAYSwWna"
      },
      "source": [
        "#### 1. **Crear una función que devuelva los documentos *Tokenizados* (una lista de listas) y con los tokens (palabras) en minúsculas.** (3ptos)\n",
        "\n",
        "* **input**: lista de documentos (lista de Strings).\n",
        "* **output**: lista de listas, en la que cada lista contiene los tokens del documento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "T-4TOCb_wWnb"
      },
      "outputs": [],
      "source": [
        "def tokenization(docs_list: list[str]):\n",
        "    tokens = list(\n",
        "        map(\n",
        "            lambda doc: ([(token.orth_.lower(), token.pos_) for token in nlp(doc)]),\n",
        "            docs_list,\n",
        "        )\n",
        "    )\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJTRkdaNwWnb"
      },
      "source": [
        "#### 2. **Crear una función que elimine los tokens que sean signos de puntuación y *Stop-Words*.** (3ptos)\n",
        "\n",
        "* **input**: lista de listas, en la que cada lista contiene los tokens del documento.\n",
        "* **output**: lista de listas, en la que cada lista contiene los tokens del documento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "u_Zij4h5wWnc"
      },
      "outputs": [],
      "source": [
        "stopwords = spacy.lang.es.stop_words.STOP_WORDS\n",
        "\n",
        "def remove_words(docs: list[list[tuple[str, str]]]):\n",
        "    return list(\n",
        "        map(\n",
        "            lambda doc: (\n",
        "                [\n",
        "                    (token[0], token[1])\n",
        "                    for token in doc\n",
        "                    if (not token[0] in stopwords and len(token[0]) > 5)\n",
        "                ]\n",
        "            ),\n",
        "            docs,\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVZeM62QwWnd"
      },
      "source": [
        "#### 3. **Crear una función que transforme cada token a su lema (*Lematización*)** (3ptos)\n",
        "\n",
        "* **input**: lista de listas, en la que cada lista contiene los tokens del documento.\n",
        "* **output**: lista de listas, en la que cada lista contiene los tokens del documento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XEtGUMxUwWnd"
      },
      "outputs": [],
      "source": [
        "def lematization(docs: list[list[tuple[str, str]]]):\n",
        "    lemm = WordNetLemmatizer()\n",
        "    return list(\n",
        "        map(lambda doc: [(lemm.lemmatize(token[0]), token[1]) for token in doc], docs)\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdz8mIcCwWne"
      },
      "source": [
        "#### 4. **Crear una función que elimine todos los tokens que no sean *Nombres* (NOUN, PROPN), *Verbos*, *Advervios* o *Adjetivos*.** (4ptos)\n",
        "\n",
        "* **input**: lista de listas, en la que cada lista contiene los tokens del documento.\n",
        "* **output**: lista de listas, en la que cada lista contiene los tokens del documento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "K4v5aGv5wWne"
      },
      "outputs": [],
      "source": [
        "def filter_words(docs: list[list[tuple[str, str]]]):\n",
        "    return list(\n",
        "        map(\n",
        "            lambda doc: [\n",
        "                token[0]\n",
        "                for token in doc\n",
        "                if (\n",
        "                    token[1] == \"NOUN\"\n",
        "                    or token[1] == \"PROPN\"\n",
        "                    or token[1] == \"VERB\"\n",
        "                    or token[1] == \"ADV\"\n",
        "                    or token[1] == \"ADJ\"\n",
        "                )\n",
        "            ],\n",
        "            docs,\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0h29B0IwWne"
      },
      "source": [
        "#### 5. **Función que dada una lista de documentos, devuelva los documentos normalizados. Este ejercicio ya esta hecho y simplemente tiene que funcionar llamando a las 4 funciones anteriores.** (3ptos)\n",
        "\n",
        "* **input**: lista de documentos (lista de Strings).\n",
        "* **output**: lista de listas, en la que cada lista contiene los tokens del documento normalizados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4rzYM9jRwWnf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['gobierno', 'español', 'sumará', 'junqueras', 'condenas', 'cumplir', 'puigdemont', 'recibido', 'gobierno', 'españa', 'puesta', 'libertad', 'carles', 'puigdemont', 'justicia', 'alemana', 'llarena', 'decidido', 'semana', 'instancias', 'ejecutivo', 'sumará', 'junqueras', 'condenas', 'cumplir', 'pdecat', 'exvicepresidente', 'cataluña', 'permanece', 'prisión', 'madrileña', 'estremera', 'noviembre', 'asumiría', 'delitos', 'atribuidos', 'carles', 'puigdemont', 'tribunal', 'supremo', 'asegura', 'expresidente', 'catalán', 'legislatura', 'quedan', 'impunes', 'junqueras', 'pagará', 'maniobra', 'ideada', 'burlar', 'justicia', 'alemana', 'esquerra', 'republicana', 'enfrenta', 'prisión', 'seguiremos', 'junqueras', 'caigan', 'carles', 'puigdemont', 'alemania', 'junqueras', 'sacrificar', 'asumiré', 'resignación', 'determinación', 'prometido', 'seguim', 'tuiteaba', 'trascender', 'decisión', 'llarena', 'fuentes', 'anónimas', 'judicial', 'barajando', 'posibilidad', 'añadir', 'junqueras', 'condenas', 'imponerse', 'futuro', 'urdangarin', 'rodrigo', 'esperanza', 'aguirre', 'delito', 'fuerza', 'ocurrido', 'semana', 'huesca', 'policía', 'incapaz', 'encontrar', 'culpable']\n"
          ]
        }
      ],
      "source": [
        "def normalization(docs_list):\n",
        "    corpus = tokenization(docs_list)\n",
        "    corpus = remove_words(corpus)\n",
        "    corpus = lematization(corpus)\n",
        "    return filter_words(corpus)\n",
        "    \n",
        "\n",
        "corpus = normalization(docs_list)\n",
        "print(corpus[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqLNb64MO9G0"
      },
      "source": [
        "#### En este ejercicio podemos ver como reducimos las palabras (tokens) del texto original, quedandonos con lo importante y normalizado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "afbcAZB-PLwr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Número de tokens del texto original: 18754\n",
            "Número de tokens distintos del texto original: 4091\n",
            "Número de tokens tras la normalización: 5480\n",
            "Número de tokens distintos tras la normalización: 2671\n"
          ]
        }
      ],
      "source": [
        "def get_tokens(corpus):\n",
        "    return [token for doc in corpus for token in doc]\n",
        "\n",
        "print('Número de tokens del texto original: ' + str(len(get_tokens(tokenization(docs_list)))))\n",
        "print('Número de tokens distintos del texto original: ' + str(len(set(get_tokens(tokenization(docs_list))))))\n",
        "print('Número de tokens tras la normalización: ' + str(len(get_tokens(normalization(docs_list)))))\n",
        "print('Número de tokens distintos tras la normalización: ' + str(len(set(get_tokens(normalization(docs_list))))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6NzHFCMwWnf"
      },
      "source": [
        "<hr>\n",
        "\n",
        "#### 6. **Crear una función que dada una lista de documentos (*corpus*) tokenizados, elimine del corpus aquellos tokens que aparecen menos de 'N' veces (N=10) en el corpus** (4ptos)\n",
        "\n",
        "* **input**: lista de listas, en la que cada lista contiene los tokens del documento normalizados.\n",
        "* **input**: 'N' -> Parámetro que nos indica el número mínimo de apariciones de la palabra en el corpus.\n",
        "* **output**: lista de listas, en la que cada lista contiene los tokens del documento normalizados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ogj3An3ywWnf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['gobierno', 'puigdemont', 'gobierno', 'españa', 'puigdemont', 'semana', 'cataluña', 'puigdemont', 'catalán', 'puigdemont', 'semana']\n",
            "['ciudadanos', 'cifuentes', 'elecciones', 'ciudadanos', 'gobierno', 'partido', 'cristina', 'cifuentes', 'ciudadanos', 'presidenta', 'elecciones', 'madrid', 'elecciones', 'cristina', 'cifuentes', 'ciudadanos', 'partido', 'gobierno', 'cifuentes', 'madrid', 'cifuentes', 'persona', 'presidenta', 'madrid', 'prensa']\n",
            "['mariano', 'presidencia', 'españa', 'partido', 'mariano', 'partido', 'presidencia', 'españa', 'prensa', 'cristina', 'cifuentes', 'presidencia', 'equipo', 'presidencia', 'mañana', 'gobierno', 'presidencia', 'ciudadanos', 'españoles', 'mariano']\n",
            "['cristina', 'cifuentes', 'presidenta', 'madrid', 'cristina', 'cifuentes', 'persona', 'mañana', 'cifuentes', 'cristina', 'cifuentes', 'persona', 'cifuentes', 'cifuentes', 'persona', 'presidencia', 'gobierno', 'españa']\n",
            "['puigdemont', 'cifuentes', 'españa', 'cataluña', 'puigdemont', 'presidenta', 'madrid', 'cristina', 'cifuentes', 'persona', 'catalán', 'cristina', 'cifuentes', 'presidencia', 'madrid', 'gobierno', 'partido', 'madrid']\n"
          ]
        }
      ],
      "source": [
        "def drop_less_frecuency_words(corpus: list[list[str]], n: int):\n",
        "    tokens = get_tokens(corpus)\n",
        "    freq = nltk.FreqDist(tokens)\n",
        "    corpus = list(\n",
        "        map(\n",
        "            lambda doc: [token for token in doc if freq[token] >= n],\n",
        "            corpus,\n",
        "        )\n",
        "    )  \n",
        "    return corpus\n",
        "\n",
        "corpus = drop_less_frecuency_words(corpus, 10)\n",
        "\n",
        "# Imprimir los 5 primeros lista por linea\n",
        "for doc in corpus[:5]:\n",
        "    print(doc)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
